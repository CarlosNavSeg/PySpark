{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9555fa-5c56-42fb-a283-8d3a01c2eaf7",
   "metadata": {
    "id": "bb9555fa-5c56-42fb-a283-8d3a01c2eaf7"
   },
   "source": [
    "# Ejercicio a Entregar   Data Frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f1e70f-9734-4e53-93b9-ee5de080ce5d",
   "metadata": {
    "id": "56f1e70f-9734-4e53-93b9-ee5de080ce5d"
   },
   "source": [
    "## Ejercicio1 - Enumera y describe al menos 5 maneras diferentes de crear un DataFame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6d572-38b2-437a-aeb8-bed3974a7336",
   "metadata": {
    "id": "8df6d572-38b2-437a-aeb8-bed3974a7336"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Método 1 desde una lista de columnas sin esquemas\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "])\n",
    "#Método 2 desde una lista de columnas con esquema\n",
    "#Haríamos lo mismo pasando el método schema como parámetro\n",
    "#el formato es variable tipo, variable tipo,\n",
    "\n",
    "\n",
    "#Método 3 desde un df de pandas\n",
    "#método createDataFrame y pasar el dataframe de pandas, hay que definir que los items del df son iteritems\n",
    "\n",
    "# método 4 desde un RDD\n",
    "#createDataFrame a un objeto RDD\n",
    "\n",
    "#método 5 desde un RDD con toDF\n",
    "#desde un rdd usando la funcion toDF() y pasandole como parametros el nombre de las columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0933b-1404-4e27-b919-9f9e77b9d572",
   "metadata": {
    "id": "91a0933b-1404-4e27-b919-9f9e77b9d572"
   },
   "source": [
    "## Ejercicio2 - ¿Se puede crear un Dataframe desde una Base de datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea0f92a-df18-49a8-bc9e-20e7c97e2790",
   "metadata": {
    "id": "2ea0f92a-df18-49a8-bc9e-20e7c97e2790"
   },
   "outputs": [],
   "source": [
    "#Ejercicio 2 -respuesta:\n",
    "#Sí, podemos crear un dataframe a partir de una base de datos utilizando el api de SQL que viene por defecto en\n",
    "#pyspark, con esta podemos crear dataframes a partir de la mayoría de bases de datos relacionales y no relacionales\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a8e85-b7e7-49ef-b1bb-bfaca47bbd83",
   "metadata": {
    "id": "522a8e85-b7e7-49ef-b1bb-bfaca47bbd83"
   },
   "source": [
    "## Ejercicio 3- A la hora de crear un dataframe desde un fichero, ¿que diferencia existe entre las siguientes líneas?\n",
    "\n",
    "df = spark.read.options(header='True',inferSchema='True').json(\"stranger.json\")\n",
    "\n",
    "df = spark.read.json(\"stranger.json\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87f276-8d7a-40b5-8965-454d167d4314",
   "metadata": {
    "id": "3a87f276-8d7a-40b5-8965-454d167d4314"
   },
   "outputs": [],
   "source": [
    "#Ejercicio 3 -respuesta .....\n",
    "\n",
    "#La primera está preformateando de tal manera que está diciendo de antemano que el dataframe tiene una\n",
    "#fila de cabecera y que infiera el esquema del archivo\n",
    "#En la segunda no hace nada de esto, lee el archivo tal cual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056c64f-0019-48f4-b726-d1aec54482e2",
   "metadata": {
    "id": "b056c64f-0019-48f4-b726-d1aec54482e2"
   },
   "source": [
    "## Ejercicio 4- ¿por qué con ambos métodos se crea el mismo esquema?\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "\n",
    "root\n",
    " |-- edad: long (nullable = true)\n",
    " |-- nombre: string (nullable = true)\n",
    " |-- sexo: string (nullable = true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c24eac-98d9-4ff6-b0ec-0b951b397dfa",
   "metadata": {
    "id": "a1c24eac-98d9-4ff6-b0ec-0b951b397dfa"
   },
   "source": [
    "Ejercicio 4 -respuesta .....  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a12076-4473-407f-a35e-2d6e71d8515d",
   "metadata": {
    "id": "40a12076-4473-407f-a35e-2d6e71d8515d"
   },
   "source": [
    "## Ejercicio 5- Dado el fichero de stranger obtener la cantidad de hombres y mujeres usando data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9414407a",
   "metadata": {
    "id": "b64a7632-758b-4497-a78c-05b8f609e36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 5 -codigo\n",
    "df = spark.read.options(header='True', inferSchema='True').json(\"stranger.json\")\n",
    "\n",
    "countWomen = df.select('nombre').where(\"sexo='M'\").count()\n",
    "countMen = df.select('nombre').where(\"sexo='H'\").count()\n",
    "print(countWomen)\n",
    "print(countMen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a3659",
   "metadata": {},
   "source": [
    "Hay 4 mujeres y 6 hombres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0709a-0c8b-4781-9ea7-c0dbfe4dc519",
   "metadata": {
    "id": "4ee0709a-0c8b-4781-9ea7-c0dbfe4dc519"
   },
   "source": [
    "## Ejercicio 6- Teniendo cargado el fichero stranger.txt  (este fichero se encuentra en el zip de la sesion2),\n",
    "Al cargarlo obtenemos una fila por cada autor pero en vez de tener 3 columnas, carga cada fila como un array.\n",
    "\n",
    "¿cómo hacemos para obtener sus 3 columnas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31bab275-7300-4cb4-bb4b-eb64a5cab691",
   "metadata": {
    "id": "31bab275-7300-4cb4-bb4b-eb64a5cab691",
    "outputId": "29898fa1-0d1e-4c37-e6a9-28f0d51fcef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|          value|\n",
      "+---------------+\n",
      "|  Eleven, 12, M|\n",
      "|  Hopper, 45, H|\n",
      "|    Will, 11, H|\n",
      "|     Max, 11, M|\n",
      "|    Mike, 11, H|\n",
      "|   Lucas, 11, H|\n",
      "|  Dustin, 11, H|\n",
      "|  Eleven, 12, M|\n",
      "|   Nancy, 23, M|\n",
      "|Jonathan, 24, H|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dftxt = spark.read.text(\"stranger.txt\")\n",
    "dftxt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2e264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53e34d3-4b33-48ba-87fc-c5df6fb1effa",
   "metadata": {
    "id": "c53e34d3-4b33-48ba-87fc-c5df6fb1effa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----+\n",
      "|  nombre|edad|sexo|\n",
      "+--------+----+----+\n",
      "|  Eleven|  12|   M|\n",
      "|  Hopper|  45|   H|\n",
      "|    Will|  11|   H|\n",
      "|     Max|  11|   M|\n",
      "|    Mike|  11|   H|\n",
      "|   Lucas|  11|   H|\n",
      "|  Dustin|  11|   H|\n",
      "|  Eleven|  12|   M|\n",
      "|   Nancy|  23|   M|\n",
      "|Jonathan|  24|   H|\n",
      "+--------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ejercio 6 completar\n",
    "\n",
    "#pista --> https://sparkbyexamples.com/spark/spark-read-text-file-rdd-dataframe/#dataframe-text\n",
    "def partir(fila):\n",
    "    elements = fila.split(\", \")\n",
    "    return elements                                   \n",
    " \n",
    "#print(partir(\"hola , fff ,ffff\"))            \n",
    "          \n",
    "    \n",
    "rdd1 = dftxt.rdd  \n",
    "#rdd1.collect()\n",
    "rddfile = rdd1.map(lambda x: partir(x[0]))\n",
    "#rddfile.collect()\n",
    "rddfile.toDF(schema=['nombre', 'edad', 'sexo']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c138fa-867e-4314-9d10-a9d82b0dd817",
   "metadata": {
    "id": "36c138fa-867e-4314-9d10-a9d82b0dd817"
   },
   "source": [
    "# Ejercios sobre la tienda virtual\n",
    "\n",
    "Los datos de la tienda virtual se descargaron en la clase anterior desde el sitio: https://www.kaggle.com/mkechinov/ecommerce-events-history-in-cosmetics-shop\n",
    "\n",
    "Nota: no se deben volver a descargar los archivos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0e1e87-c588-4e8c-b17a-398e56245ae2",
   "metadata": {
    "id": "db0e1e87-c588-4e8c-b17a-398e56245ae2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#cargamos los datos de la tienda virtual\n",
    "\n",
    "\n",
    "dfTienda = spark.read.options(header='True', inferSchema='True').csv(\"./archive(3)/*.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60376a6-6b46-4d4e-895c-511ba9f07308",
   "metadata": {
    "id": "e60376a6-6b46-4d4e-895c-511ba9f07308"
   },
   "source": [
    "## Ejercicio 7 :  ¿Obtener las 2 sesiones  en las que menos productos diferentes se hayan comprado? Mostar las dos sesiones junto con el número  productos diferentes comprados en cada una de ellas\n",
    "\n",
    "Nota=  filtar por event_type = purchase\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48f171bb-7fa7-4f69-a27e-5a308879ef9a",
   "metadata": {
    "id": "48f171bb-7fa7-4f69-a27e-5a308879ef9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:=====================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        user_session|count|\n",
      "+--------------------+-----+\n",
      "|b2167f2d-7a93-4c0...|    1|\n",
      "|6a541a8c-1e17-466...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "leastBoughtSessions = dfTienda.filter(\"event_type='purchase'\").groupBy(\"user_session\").count()\n",
    "leastBoughtSessions.orderBy(\"count\",ascending=True).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e30050-7060-41b9-99a4-7f942ac70863",
   "metadata": {
    "id": "25e30050-7060-41b9-99a4-7f942ac70863"
   },
   "source": [
    "#Ejercicio 8:  Dadas las 3 marcas más polulares de la tienda\n",
    "1- obtener el numero de usuarios que han comprado alguna de esas marcas\n",
    "\n",
    "2) obtener el nombre/id de los usuarios que han comprado alguna de esas marcas\n",
    "\n",
    "3) obtener el total de dinero que se ha vendido de cada una de las marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abd133af-269e-49ed-bdc7-46913240db89",
   "metadata": {
    "id": "abd133af-269e-49ed-bdc7-46913240db89"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:=====================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| brand| count|\n",
      "+------+------+\n",
      "|  null|549693|\n",
      "|runail|111408|\n",
      "| irisk| 73806|\n",
      "+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "marcas= df.filter(\"event_type='purchase'\").groupBy(\"brand\").count()\n",
    "marcas.orderBy(\"count\", ascending=False).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8abf6d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:=====================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "boughtBrandUser = df.select('user_id').filter(\"event_type='purchase' and brand = 'null' or brand = 'runail' or brand= 'irisk'\").distinct().count()\n",
    "print(boughtBrandUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "350b0267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  user_id|\n",
      "+---------+\n",
      "|494077766|\n",
      "|560109803|\n",
      "|494077766|\n",
      "|576802932|\n",
      "|576802932|\n",
      "|576802932|\n",
      "|494077766|\n",
      "|494077766|\n",
      "|579970581|\n",
      "|568755469|\n",
      "|576802932|\n",
      "|482493001|\n",
      "|544461907|\n",
      "|509445281|\n",
      "|494077766|\n",
      "|556730134|\n",
      "|494077766|\n",
      "|499259978|\n",
      "|513026898|\n",
      "|513026898|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boughtBrandUser = df.select('user_id').filter(\"event_type='purchase' and brand = 'null' or brand = 'runail' or brand= 'irisk'\")\n",
    "boughtBrandUser.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cc6e44",
   "metadata": {},
   "source": [
    "3) obtener el total de dinero que se ha vendido de cada una de las marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4183f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "productsIdWithBrand = df.select('product_id').filter(\"brand = 'null' or brand = 'runail' or brand= 'irisk'\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60ef2dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:=====================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "moneyWon = df.select('price').filter(col(\"product_id\").isin(productsIdWithBrand['product_id'])).filter(\"event_type='purchase'\").count()\n",
    "print(moneyWon)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
